{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "7d49a30c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "id": "c3374add",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CrossStitchBlock(torch.nn.Module):\n",
    "    \"\"\"\n",
    "    \"\"\"\n",
    "    def __init__(self,\n",
    "                 num_tasks: int = 2,\n",
    "                 num_subspaces: int = 1):\n",
    "        super(CrossStitchBlock, self).__init__()\n",
    "        \n",
    "        self.num_tasks = num_tasks\n",
    "        self.num_subspaces = num_subspaces\n",
    "        \n",
    "        # initialize using random uniform distribution as suggested in Section 5.1\n",
    "        self.cross_stitch_kernel = torch.FloatTensor(\n",
    "                                                self.num_tasks * self.num_subspaces,\n",
    "                                                self.num_tasks * self.num_subspaces).uniform_(\n",
    "            0.0, 1.0\n",
    "        )\n",
    "        # normalize, so that each row will be convex linear combination\n",
    "        normalizer = torch.sum(self.cross_stitch_kernel, 0, keepdim=True)\n",
    "        self.cross_stitch_kernel = self.cross_stitch_kernel / normalizer\n",
    "    \n",
    "\n",
    "    def forward(self, inputs: torch.Tensor) -> torch.Tensor:\n",
    "        print(\"inputs\", inputs)\n",
    "        print()        \n",
    "\n",
    "        # concatenate nth element of each input task\n",
    "        x = torch.cat([torch.unsqueeze(i, -1) for i in inputs], -1)\n",
    "        print(\"x\", x, x.size())\n",
    "        print()\n",
    "        \n",
    "        print(f\"the cross stitch kernel after normalization: \\n {self.cross_stitch_kernel}\")\n",
    "        print()\n",
    "\n",
    "        # multiply every element of the input with the cross-stitch kernel\n",
    "        stitched_output = torch.matmul(x, self.cross_stitch_kernel)\n",
    "        print(f\"stitched_output:\\n{stitched_output} {stitched_output.size()}\")\n",
    "\n",
    "        n, batch, seq, d = x.size()\n",
    "        # index need to be of the same dimension size as source tensor\n",
    "        index = torch.zeros(n, batch, seq, 1, dtype=torch.int64)\n",
    "\n",
    "        # split result into tensors corresponding to specific tasks and return\n",
    "        # to task-specific lists\n",
    "        outputs = [\n",
    "            torch.flatten(torch.gather(e, dim=-1, index=index), start_dim=2)\n",
    "            for e in torch.split(stitched_output, 1, -1)\n",
    "        ]\n",
    "\n",
    "        assert len(outputs) == self.num_tasks\n",
    "        return outputs\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "id": "4a70b38f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "inputs [tensor([[[-0.3865, -0.4061],\n",
      "         [-0.7158,  0.4503]]]), tensor([[[-0.5347,  0.0838],\n",
      "         [-0.6797, -0.9894]]])]\n",
      "\n",
      "x tensor([[[[-0.3865, -0.5347],\n",
      "          [-0.4061,  0.0838]],\n",
      "\n",
      "         [[-0.7158, -0.6797],\n",
      "          [ 0.4503, -0.9894]]]]) torch.Size([1, 2, 2, 2])\n",
      "\n",
      "the cross stitch kernel after normalization: \n",
      " tensor([[0.5233, 0.6085],\n",
      "        [0.4767, 0.3915]])\n",
      "\n",
      "stitched_output:\n",
      "tensor([[[[-0.4572, -0.4445],\n",
      "          [-0.1726, -0.2143]],\n",
      "\n",
      "         [[-0.6986, -0.7017],\n",
      "          [-0.2359, -0.1134]]]]) torch.Size([1, 2, 2, 2])\n",
      "A A 0.5233339667320251\n",
      "A B 0.608464241027832\n",
      "B A 0.47666603326797485\n",
      "B B 0.39153578877449036\n",
      "tensor([[0.5233, 0.6085],\n",
      "        [0.4767, 0.3915]])\n"
     ]
    }
   ],
   "source": [
    "cross_stitch = CrossStitchBlock()\n",
    "\n",
    "inputs = [torch.randn(1, 2, 2) for _ in range(2)]\n",
    "output = cross_stitch(inputs)\n",
    "\n",
    "\n",
    "for i, task_i in enumerate([\"A\", \"B\"]):\n",
    "    for j, task_j in enumerate([\"A\", \"B\"]):\n",
    "        print(f\"{task_i} {task_j} {cross_stitch.cross_stitch_kernel[i][j]}\")\n",
    "\n",
    "print(cross_stitch.cross_stitch_kernel)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "d6077a7f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.3007, 0.3849, 0.8875, 0.9102],\n",
      "        [0.0386, 0.0050, 0.3250, 0.7348],\n",
      "        [0.8492, 0.1911, 0.7196, 0.6900],\n",
      "        [0.5646, 0.5089, 0.7480, 0.5455]])\n"
     ]
    }
   ],
   "source": [
    "cross_stitch_kernel = torch.FloatTensor(\n",
    "                                        2 * 2,\n",
    "                                        2 * 2).uniform_(\n",
    "    0.0, 1.0\n",
    ")\n",
    "print(cross_stitch_kernel)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "17aaa448",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[tensor([[[ 0.3692,  0.3376, -0.1420,  0.1280],\n",
      "         [ 0.7821,  1.6744,  1.9704, -1.8366]],\n",
      "\n",
      "        [[-0.1301,  1.4170, -0.1446, -0.6735],\n",
      "         [ 0.3292,  0.7654, -0.4625, -0.0124]]]), tensor([[[ 1.8255, -0.0959, -0.1649,  0.3290],\n",
      "         [-0.1835,  0.4722,  0.4786,  1.2735]],\n",
      "\n",
      "        [[ 0.3063, -1.4406,  0.7297, -1.0241],\n",
      "         [ 0.6807, -0.9482, -0.3396, -0.2354]]])]\n"
     ]
    }
   ],
   "source": [
    "inputs = [torch.randn(2, 2, 4) for _ in range(2)]\n",
    "print(inputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "54213721",
   "metadata": {},
   "outputs": [],
   "source": [
    "o = []\n",
    "\n",
    "for i in inputs:\n",
    "    s1, s2 = i.split(2, dim= -1) # split in half on last dim\n",
    "    x = torch.cat([s1, s2], 0)\n",
    "    o.append(x)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "meta_parser",
   "language": "python",
   "name": "meta_parser"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
